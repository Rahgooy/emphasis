{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creating conditional model & predicting  \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer as stemmer\n",
    "import pickle \n",
    "\n",
    "class WordConditionalModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__words_matrix = 0\n",
    "        self.__bios_matrix = 0\n",
    "        self.__model = 0\n",
    "        self.__words = []\n",
    "        self.__none_words_vocab = []\n",
    "    \n",
    "    def __build_matrix(self, number_of_sentences, number_of_words):\n",
    "        word_matrix = np.zeros((number_of_sentences, number_of_words))\n",
    "        return word_matrix\n",
    "\n",
    "\n",
    "    def __represent_sentences_as_matrix(self, words_lsts):\n",
    "        matrix = self.__build_matrix(len(words_lsts * 9), len(self.__words))\n",
    "        for i in range(len(words_lsts)):\n",
    "            for j in range(len(words_lsts[i])):\n",
    "                mj = self.__words.index( stemmer().stem(words_lsts[i][j].lower()))\n",
    "                matrix[i*9:(i+1)*9, mj] = 1\n",
    "        return matrix\n",
    "\n",
    "    def __represent_bios_as_matrix(self, bios_lsts, words_lsts):\n",
    "        matrix = self.__build_matrix(len(words_lsts * 9), len(self.__words))\n",
    "        for i in range(len(words_lsts)):\n",
    "            for j in range(len(words_lsts[i])):\n",
    "                d = self.__words.index( stemmer().stem(words_lsts[i][j].lower()))\n",
    "                for m in range(9):\n",
    "                    if bios_lsts[i][j][m * 2] == \"I\" or bios_lsts[i][j][m * 2] == \"B\":\n",
    "                        matrix[(i * 9) + m][d] = 1\n",
    "        return matrix\n",
    "\n",
    "    def __calculate_condetional_probs(self, w_i, w_j):\n",
    "        occurrenece_of_wi_and_wj, bold_wi = 0, 0\n",
    "        occurrenece_of_wi_and_wj = (self.__words_matrix[:, w_i] * self.__words_matrix[:, w_j]).sum()\n",
    "        y = self.__words_matrix[:, w_i] * self.__words_matrix[:, w_j]\n",
    "        bold_wi = (y * self.__bios_matrix[:, w_i]).sum()\n",
    "        self.__model[w_i][w_j] = (bold_wi / occurrenece_of_wi_and_wj) if occurrenece_of_wi_and_wj else 0\n",
    "        #print(\"[{}], [{}] = {}\".format(self.__words[w_i], self.__words[w_j], self.__model[w_i][w_j]))\n",
    "\n",
    "    def fit(self, words_lsts, bios_lsts):\n",
    "        print(\"training WordConditionalModel....\")\n",
    "        self.__words = []\n",
    "        words_vocab = [stemmer().stem(word.lower()) for innerlist in words_lsts for word in innerlist]\n",
    "        for word in words_vocab:\n",
    "            if word not in self.__words:\n",
    "                self.__words.append(word)\n",
    "        \n",
    "        self.__model = self.__build_matrix(len(self.__words), len(self.__words))\n",
    "        self.__words_matrix = self.__represent_sentences_as_matrix(words_lsts)\n",
    "        self.__bios_matrix = self.__represent_bios_as_matrix(bios_lsts, words_lsts)\n",
    "        print(\"vocab lenghts: \" , len(self.__words))\n",
    "        for i in range(len(self.__words)):\n",
    "            if i%100 == 0:\n",
    "                print(i , end = ' ')\n",
    "            for j in range(len(self.__words)):\n",
    "                self.__calculate_condetional_probs(i, j)\n",
    "        print()\n",
    "\n",
    "    def predict(self, word_lsts, words_id):\n",
    "        self.__get_id_of_none_wordvocab(word_lsts, words_id)\n",
    "        print(self.__none_words_vocab)\n",
    "        predictions = []\n",
    "        for i in range(len(word_lsts)):\n",
    "            prediction = []\n",
    "            for j in range(len(word_lsts[i])):\n",
    "                word_ij = stemmer().stem(word_lsts[i][j].lower())\n",
    "                if word_ij in self.__words:\n",
    "                    w_i = self.__words.index( word_ij )\n",
    "                    s = 0\n",
    "                    for m in range(len(word_lsts[i])):\n",
    "                        word_im = stemmer().stem(word_lsts[i][m].lower())\n",
    "                        if word_im in self.__words:\n",
    "                            w_j = self.__words.index( word_im )\n",
    "                            s += self.__model[w_i][w_j]\n",
    "                    prediction.append(s / len(word_lsts[i]))\n",
    "                else:\n",
    "                    prediction.append(0)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def __get_id_of_none_wordvocab(self, word_lsts, words_id):\n",
    "        self.__none_words_vocab = []\n",
    "        for i in range(len(word_lsts)):\n",
    "            for j in range(len(word_lsts[i])):\n",
    "                word_ij = stemmer().stem(word_lsts[i][j].lower())\n",
    "                if word_ij not in self.__words:\n",
    "                    self.__none_words_vocab.append(words_id[i][j])\n",
    "        \n",
    "    \n",
    "    def save(self, path):\n",
    "        model = {\"__words\":self.__words, \"__model\":self.__model, \"__none_words\":self.__none_words_vocab}\n",
    "        pickle.dump(model,open(path,\"wb\"))\n",
    "\n",
    "    def load(self, path):\n",
    "        model = pickle.load(open(path, \"rb\"))\n",
    "        self.__words, self.__model, self.__none_words_vocab = model[\"__words\"], model[\"__model\"], model[\"__none_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Read_data_and_Write_results as rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_id, word_lsts, bio_lsts, _, _, _ = rw.read_data(\"datasets/just_train.txt\")\n",
    "word_id, word_list, bio_list, _, truth, _ = rw.read_data(\"datasets/just_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WordConditionalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training WordConditionalModel....\n",
      "vocab lenghts:  15\n",
      "0 \n"
     ]
    }
   ],
   "source": [
    "model.fit(word_lsts, bio_lsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q_4_0', 'Q_4_1', 'Q_4_2', 'Q_4_4', 'Q_4_6', 'Q_4_7', 'Q_4_8', 'Q_4_9', 'Q_4_10']\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(word_list, word_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8888888888888888, 0.3703703703703704, 0.7777777777777778], [0.04444444444444444, 0.33333333333333337, 0.0, 0.6666666666666667, 0.0, 0.04444444444444444, 0.33333333333333337, 0.0, 0.7777777777777778, 0.11111111111111113], [0.0, 0.0, 0.5555555555555555, 0.0, 0.22222222222222227, 0.22222222222222227, 0.5555555555555555, 0.11111111111111113], [0, 0, 0, 0.018518518518518517, 0, 0.037037037037037035, 0, 0, 0, 0, 0, 0.027777777777777776]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.8888888888888888', '0.4444444444444444', '0.7777777777777778'], ['0.0', '0.3333333333333333', '0.0', '0.6666666666666666', '0.0', '0.0', '0.1111111111111111', '0.0', '0.7777777777777778', '0.1111111111111111'], ['0.0', '0.0', '0.5555555555555556', '0.0', '0.2222222222222222', '0.2222222222222222', '0.5555555555555556', '0.1111111111111111'], ['0.0', '0.0', '0.0', '0.0', '0.2222222222222222', '0.1111111111111111', '0.3333333333333333', '0.0', '0.7777777777777778', '0.7777777777777778', '0.6666666666666666', '0.2222222222222222']]\n"
     ]
    }
   ],
   "source": [
    "print(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction[0.8888888888888888] - truth[0.8888888888888888] = 0.0\n",
      "prediction[0.3703703703703704] - truth[0.4444444444444444] = 0.07407407407407401\n",
      "prediction[0.7777777777777778] - truth[0.7777777777777778] = 0.0\n",
      "prediction[0.04444444444444444] - truth[0.0] = 0.04444444444444444\n",
      "prediction[0.33333333333333337] - truth[0.3333333333333333] = 5.551115123125783e-17\n",
      "prediction[0.0] - truth[0.0] = 0.0\n",
      "prediction[0.6666666666666667] - truth[0.6666666666666666] = 1.1102230246251565e-16\n",
      "prediction[0.0] - truth[0.0] = 0.0\n",
      "prediction[0.04444444444444444] - truth[0.0] = 0.04444444444444444\n",
      "prediction[0.33333333333333337] - truth[0.1111111111111111] = 0.22222222222222227\n",
      "prediction[0.0] - truth[0.0] = 0.0\n",
      "prediction[0.7777777777777778] - truth[0.7777777777777778] = 0.0\n",
      "prediction[0.11111111111111113] - truth[0.1111111111111111] = 2.7755575615628914e-17\n",
      "prediction[0.0] - truth[0.0] = 0.0\n",
      "prediction[0.0] - truth[0.0] = 0.0\n",
      "prediction[0.5555555555555555] - truth[0.5555555555555556] = 1.1102230246251565e-16\n",
      "prediction[0.0] - truth[0.0] = 0.0\n",
      "prediction[0.22222222222222227] - truth[0.2222222222222222] = 5.551115123125783e-17\n",
      "prediction[0.22222222222222227] - truth[0.2222222222222222] = 5.551115123125783e-17\n",
      "prediction[0.5555555555555555] - truth[0.5555555555555556] = 1.1102230246251565e-16\n",
      "prediction[0.11111111111111113] - truth[0.1111111111111111] = 2.7755575615628914e-17\n",
      "prediction[0] - truth[0.0] = 0.0\n",
      "prediction[0] - truth[0.0] = 0.0\n",
      "prediction[0] - truth[0.0] = 0.0\n",
      "prediction[0.018518518518518517] - truth[0.0] = 0.018518518518518517\n",
      "prediction[0] - truth[0.2222222222222222] = 0.2222222222222222\n",
      "prediction[0.037037037037037035] - truth[0.1111111111111111] = 0.07407407407407407\n",
      "prediction[0] - truth[0.3333333333333333] = 0.3333333333333333\n",
      "prediction[0] - truth[0.0] = 0.0\n",
      "prediction[0] - truth[0.7777777777777778] = 0.7777777777777778\n",
      "prediction[0] - truth[0.7777777777777778] = 0.7777777777777778\n",
      "prediction[0] - truth[0.6666666666666666] = 0.6666666666666666\n",
      "prediction[0.027777777777777776] - truth[0.2222222222222222] = 0.19444444444444442\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prediction)):\n",
    "    for j in range(len(prediction[i])):\n",
    "        print(\"prediction[{}] - truth[{}] = {}\".format(prediction[i][j], truth[i][j],\n",
    "                                                       abs(float(prediction[i][j])- float(truth[i][j]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization_of_errors(prediction, truth, range1, range2, range3, range4):\n",
    "    counter1, counter2, counter3, counter4 = 0, 0, 0, 0\n",
    "    for i in range(len(prediction)):\n",
    "        for j in range(len(prediction[i])):\n",
    "            if abs(float(prediction[i][j])- float(truth[i][j])) <= range1:\n",
    "                counter1 += 1\n",
    "            elif abs(float(prediction[i][j])- float(truth[i][j])) > range1 and abs(float(prediction[i][j])- float(truth[i][j])) <= range2:\n",
    "                counter2 += 1\n",
    "            elif abs(float(prediction[i][j])- float(truth[i][j])) > range2 and abs(float(prediction[i][j])- float(truth[i][j])) <= range3:\n",
    "                counter3 += 1\n",
    "            elif abs(float(prediction[i][j])- float(truth[i][j])) > range3 and abs(float(prediction[i][j])- float(truth[i][j])) <= range4:\n",
    "                counter4 += 1\n",
    "    print(\"counter1 = [{}]\".format(counter1))\n",
    "    print(\"counter2 = [{}]\".format(counter2))\n",
    "    print(\"counter3 = [{}]\".format(counter3))\n",
    "    print(\"counter4 = [{}]\".format(counter4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter1 = [13]\n",
      "counter2 = [16]\n",
      "counter3 = [1]\n",
      "counter4 = [1]\n"
     ]
    }
   ],
   "source": [
    "visualization_of_errors(prediction, truth, 0, 0.25, 0.5, 0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import Read_data_and_Write_results as rw\n",
    "from collections import defaultdict\n",
    "from nltk.stem import PorterStemmer as stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"train.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    dataset = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, words = [], []\n",
    "for word in dataset[1:]:\n",
    "    if len(word) == 0:\n",
    "        sentences.append(words)\n",
    "        words = []\n",
    "    else:\n",
    "        words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sentences, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(dataset):\n",
    "    data = ['']\n",
    "    for words in dataset:\n",
    "        data.append('\\n'.join(words))\n",
    "        data.append('')\n",
    "    return '\\n'.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"test.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "    f.write(build_dataset(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"semi_train.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "    f.write(build_dataset(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, word_lsts, _, bio_freqs, _, _  = rw.read_data(\"semi_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_freqs_word = defaultdict(int)\n",
    "occurrences_word = defaultdict(int)\n",
    "for i in range(len(bio_freqs)):\n",
    "    for j in range(len(bio_freqs[i])):\n",
    "        bio = bio_freqs[i][j].split(\"|\")\n",
    "        word_stem = stemmer().stem(word_lsts[i][j].lower())\n",
    "        bio_freqs_word[word_stem] += (int(bio[0]) + int(bio[1]))\n",
    "        occurrences_word[word_stem] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(bio_freqs_word, occurrences):\n",
    "    model = {}\n",
    "    for word ,bio_freq in bio_freqs_word.items():\n",
    "            model[word] = (bio_freq / ( occurrences[word] * 9))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(bio_freqs_word, occurrences_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_id_lsts, word_lsts, _, _, _, _  = rw.read_data(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word_lsts, model):\n",
    "    predictions = []\n",
    "    for i in range(len(word_lsts)):\n",
    "        word_prediction = []\n",
    "        for j in range(len(word_lsts[i])):\n",
    "            word_stem = stemmer().stem(word_lsts[i][j].lower())\n",
    "            if word_stem in model.keys():\n",
    "                word_prediction.append(model[word_stem])\n",
    "            else:\n",
    "                word_prediction.append(0)\n",
    "        predictions.append(word_prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(word_lsts, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw.write_results(word_id_lsts, word_lsts, predictions, \"result.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
